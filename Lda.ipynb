{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/55/55-h/55-h.htm\"\n",
        "html = urlopen(url).read()\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")"
      ],
      "metadata": {
        "id": "kySsad6pzKfB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()"
      ],
      "metadata": {
        "id": "Pve881P5zV51"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = soup.get_text()\n",
        "documents = []\n",
        "documents.append(text)"
      ],
      "metadata": {
        "id": "NUknS5YezYaV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.gutenberg.org/files/54/54-h/54-h.htm\"\n",
        "html = urlopen(url).read()\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "text = soup.get_text()\n",
        "documents.append(text)\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/33361/33361-h/33361-h.htm\"\n",
        "html = urlopen(url).read()\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "text = soup.get_text()\n",
        "documents.append(text)\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/22566/22566-h/22566-h.htm\"\n",
        "html = urlopen(url).read()\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "text = soup.get_text()\n",
        "documents.append(text)\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/26624/26624-h/26624-h.htm\"\n",
        "html = urlopen(url).read()\n",
        "soup = BeautifulSoup(html, features=\"html.parser\")\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "text = soup.get_text()\n",
        "documents.append(text)"
      ],
      "metadata": {
        "id": "iDaJDBePzadS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "vPezbCC1ze99"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Your text data\n",
        "#corpus = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\"]\n",
        "\n",
        "# Create a CountVectorizer instance\n",
        "cv = CountVectorizer()\n",
        "\n",
        "# Fit and transform the data\n",
        "df = cv.fit_transform(documents)\n",
        "\n",
        "# Get the feature names using get_feature_names_out()\n",
        "vocab = cv.get_feature_names_out()\n",
        "\n",
        "# Print the feature names\n"
      ],
      "metadata": {
        "id": "D3Acbiv8ziDB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (df[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QDdz_kOzjjs",
        "outputId": "108b11d6-7b63-4ade-8462-b3535ebd987f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 8068)\t3198\n",
            "  (0, 6153)\t89\n",
            "  (0, 3799)\t99\n",
            "  (0, 2714)\t14\n",
            "  (0, 5459)\t976\n",
            "  (0, 9001)\t28\n",
            "  (0, 8982)\t44\n",
            "  (0, 5594)\t169\n",
            "  (0, 1344)\t119\n",
            "  (0, 3400)\t5\n",
            "  (0, 893)\t5\n",
            "  (0, 8101)\t196\n",
            "  (0, 4377)\t284\n",
            "  (0, 3330)\t354\n",
            "  (0, 8580)\t28\n",
            "  (0, 593)\t18\n",
            "  (0, 596)\t4\n",
            "  (0, 4216)\t544\n",
            "  (0, 8508)\t15\n",
            "  (0, 7635)\t19\n",
            "  (0, 551)\t1738\n",
            "  (0, 5169)\t24\n",
            "  (0, 5546)\t65\n",
            "  (0, 5665)\t2\n",
            "  (0, 9034)\t19\n",
            "  :\t:\n",
            "  (0, 5610)\t1\n",
            "  (0, 2548)\t1\n",
            "  (0, 5049)\t1\n",
            "  (0, 404)\t1\n",
            "  (0, 8786)\t1\n",
            "  (0, 2064)\t1\n",
            "  (0, 1408)\t1\n",
            "  (0, 6144)\t1\n",
            "  (0, 5052)\t1\n",
            "  (0, 3880)\t1\n",
            "  (0, 5535)\t1\n",
            "  (0, 7087)\t1\n",
            "  (0, 6140)\t1\n",
            "  (0, 4809)\t1\n",
            "  (0, 5321)\t1\n",
            "  (0, 8692)\t1\n",
            "  (0, 1841)\t1\n",
            "  (0, 5288)\t1\n",
            "  (0, 2724)\t1\n",
            "  (0, 4884)\t1\n",
            "  (0, 5812)\t1\n",
            "  (0, 3041)\t1\n",
            "  (0, 6139)\t1\n",
            "  (0, 7816)\t1\n",
            "  (0, 5332)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components = 4, doc_topic_prior=1)\n",
        "lda.fit(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "BRm_2XNsztPl",
        "outputId": "f9d6691d-d632-4926-aeef-6a153c3e72e0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(doc_topic_prior=1, n_components=4)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(doc_topic_prior=1, n_components=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(doc_topic_prior=1, n_components=4)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "topic_words = {}\n",
        "n_top_words = 10\n",
        "for topic, comp in enumerate(lda.components_):\n",
        "    # for the n-dimensional array \"arr\":\n",
        "    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n",
        "    # which contains the indices that would sort arr in a descending fashion\n",
        "    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n",
        "    # element in arr that should be at the ith index in ranked_array\n",
        "    # ex. arr = [3,7,1,0,3,6]\n",
        "    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n",
        "    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n",
        "    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)\n",
        "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
        "\n",
        "    # store the words most relevant to the topic\n",
        "    topic_words[topic] = [vocab[i] for i in word_idx]\n",
        "\n",
        "for topic, words in topic_words.items():\n",
        "    print('Topic: %d' % topic)\n",
        "    print('  %s' % ', '.join(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjuLIJNhzzX-",
        "outputId": "9e2b4ff5-d27b-4e30-a21d-688e6b446ebe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0\n",
            "  ripped, giv, resounding, ta, gaz, reseated, unrolling, unroll, geth, gi\n",
            "Topic: 1\n",
            "  ripped, giv, resounding, ta, gaz, reseated, unrolling, unroll, geth, gi\n",
            "Topic: 2\n",
            "  the, and, to, of, in, you, it, was, that, he\n",
            "Topic: 3\n",
            "  ripped, giv, resounding, ta, gaz, reseated, unrolling, unroll, geth, gi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# we can add this to the tokenization step\n",
        "cv = CountVectorizer(stop_words='english')\n",
        "df = cv.fit_transform(documents)\n",
        "vocab = cv.get_feature_names_out()"
      ],
      "metadata": {
        "id": "Meh3MxN6z2Qk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components = 4, doc_topic_prior=1)\n",
        "lda.fit(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "e7cOURJs07FG",
        "outputId": "92b499c7-ac6d-4933-a9ab-77d99559fb0f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(doc_topic_prior=1, n_components=4)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(doc_topic_prior=1, n_components=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(doc_topic_prior=1, n_components=4)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_words = {}\n",
        "n_top_words = 10\n",
        "for topic, comp in enumerate(lda.components_):\n",
        "    # for the n-dimensional array \"arr\":\n",
        "    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n",
        "    # which contains the indices that would sort arr in a descending fashion\n",
        "    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n",
        "    # element in arr that should be at the ith index in ranked_array\n",
        "    # ex. arr = [3,7,1,0,3,6]\n",
        "    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n",
        "    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n",
        "    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)\n",
        "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
        "\n",
        "    # store the words most relevant to the topic\n",
        "    topic_words[topic] = [vocab[i] for i in word_idx]\n",
        "\n",
        "for topic, words in topic_words.items():\n",
        "    print('Topic: %d' % topic)\n",
        "    print('  %s' % ', '.join(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJac3L4v1CAQ",
        "outputId": "62f04c38-5587-45aa-96ea-c3f4ee8b86ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0\n",
            "  dorothy, said, pg, little, scarecrow, oz, wizard, asked, girl, gutenberg\n",
            "Topic: 1\n",
            "  foxes, shaggy, rug, dance, bridge, candy, glowed, straighten, housework, melting\n",
            "Topic: 2\n",
            "  said, man, dorothy, scarecrow, shaggy, tip, tin, bright, head, asked\n",
            "Topic: 3\n",
            "  foxes, shaggy, rug, dance, bridge, candy, glowed, straighten, housework, melting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TFqkqJLm1Ezr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}